{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd3d964",
   "metadata": {},
   "source": [
    "# Silver Layer ðŸ¥ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f15fbb6",
   "metadata": {},
   "source": [
    "## Step 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f484022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c38efd5",
   "metadata": {},
   "source": [
    "## Step 2: Load the Bronze Layer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba86e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/bronze/bronze_mario.parquet') # read bronze parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f74ae3",
   "metadata": {},
   "source": [
    "## Step 3: Generalized Data Validation and Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43432699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_null_columns(df, threshold=0.2):\n",
    "    \"\"\"Remove (drop) mostly-empty columns. Threshold=0.2 â†’ means 20%. â†’ means 20% missing allowed.\"\"\"\n",
    "    null_percentage = df.isnull().mean()\n",
    "    columns_to_keep = null_percentage[null_percentage < threshold].index \n",
    "\n",
    "    if len(columns_to_keep) == len(df.columns):\n",
    "        print('no columns remvoed')\n",
    "    else:\n",
    "        print(f'removing: {[c for c in df.columns if c not in columns_to_keep]}')\n",
    "\n",
    "    return df[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109d82e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df, columns_defaults: dict):\n",
    "    \"\"\"Fill missing values with assigned defaults in columns default dictionary.\"\"\"\n",
    "    for column, default_value in columns_defaults.items():\n",
    "        df[column] = df[column].fillna(default_value)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e043de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_column_types(df, columns_types: dict):\n",
    "    \"\"\"Convert columns to desired data types.\"\"\"\n",
    "    try:\n",
    "        for column, dtype in columns_types.items():\n",
    "            df[column] = df[column].astype(dtype)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'{column} caused an issue')\n",
    "        raise e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafa1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(df, columns: list):\n",
    "    \"\"\"Remove punctuation from string type columns\"\"\"\n",
    "    for c in columns:\n",
    "        df.loc[:,c] = df[c].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d9e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_spaces(df, columns: list):\n",
    "    \"\"\"Remove leading and trailing spaces from specific string columns\"\"\"\n",
    "    for c in columns:\n",
    "        df.loc[:, c] = df[c].astype(str).str.strip()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca862d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_formats(df, expected_formats: dict):\n",
    "    \"\"\"Check the schema of the table to validate formats\"\"\"\n",
    "    incorrect_formats = []\n",
    "    for column, datatype in df.dtypes.to_dict().items():\n",
    "        expected_type = expected_formats.get(column)\n",
    "        if expected_type != datatype:\n",
    "            incorrect_formats.append((column, datatype, expected_type))\n",
    "\n",
    "    incorrect_columns = [c[0] for c in incorrect_formats]\n",
    "    correct_format_count = len([c for c in df.columns if c not in incorrect_columns])\n",
    "    if incorrect_formats:\n",
    "        print('Below are incorrect formats')\n",
    "        print(\"-\"* 50)\n",
    "        print(f'correct column count: {correct_format_count}')\n",
    "        return pd.DataFrame(incorrect_formats, columns=['Column', 'Actual', 'Expected'])\n",
    "    else:\n",
    "        print('Validation Complete, no discrepancies')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18187b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_similarity(word1: str, word2: str) -> float:\n",
    "    '''Check the similarity between two words using Jaccard Similarity'''\n",
    "    if pd.isna(word1) or pd.isna(word2):\n",
    "        return 0.0\n",
    "\n",
    "    word_set1 = set(word1)\n",
    "    word_set2 = set(word2)\n",
    "\n",
    "    intersection = word_set1.intersection(word_set2)\n",
    "    intersection_count = len(intersection)\n",
    "\n",
    "    total_char_count = len(word_set1.union(word_set2))\n",
    "\n",
    "    similarity = intersection_count / total_char_count\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a64d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_misspelling(dataframe: pd.DataFrame, column: str, similarity_threshold: float) -> pd.DataFrame:\n",
    "    '''\n",
    "    Input a pandas dataframe, a specific column, and similarity threshold from 0-1 to get all values that are similar\n",
    "    dataframe: Pandas DataFrame\n",
    "    column: String representing a column from Dataframe\n",
    "    similarity_threshold: Float representing values from 0 to 1 or 0 to 100% similarity\n",
    "    '''\n",
    "\n",
    "    all_unique_values = list(set(dataframe[column].tolist()))\n",
    "\n",
    "    similarity_list = []\n",
    "    for n in range(len(all_unique_values)):\n",
    "        value1 = all_unique_values[n]\n",
    "        for n2 in range(n + 1, len(all_unique_values)):\n",
    "            value2 = all_unique_values[n2]\n",
    "            similarity = round(check_similarity(value1, value2), 4)\n",
    "            if similarity >= similarity_threshold:\n",
    "                similarity_list.append([value1, value2, similarity])\n",
    "    return pd.DataFrame(similarity_list, columns=['name1', 'name2', 'similarity'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e5ae33",
   "metadata": {},
   "source": [
    "## Step 4: Apply Validations and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f399597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1b240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feec60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().mean() * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64acbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_null_columns(df, threshold=.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c769ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_missing_values(df, {'Player Name': 'Unknown Player', 'Team': 'Unknown Team', 'Kart Racing Rank': 'Unknown Rank', 'Mushroom Cup Participation': 'Unknown'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597d6c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().mean() * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f83223",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_punctuation(df, ['Kart Role'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33695a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_misspelling(df, 'Player Name', .8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b3fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_formats = {\n",
    "    'Player Name': 'string',\n",
    "    'Team': 'string',\n",
    "    'Kart Racing Rank': 'string',\n",
    "    'Mushroom Cup Participation': 'bool',\n",
    "    'Participation in Battle Mode': 'bool',\n",
    "    'Platforming Rank': 'string', \n",
    "    'Boss Battle Rank': 'string',\n",
    "    'Power-Ups Owned': 'string', \n",
    "    'Kart Role': 'string',\n",
    "    'Power-Ups Used': 'int32',\n",
    "    'Team Points': 'int32',\n",
    "    'Levels Completed': 'int32',\n",
    "    'Lives Lost': 'int32', \n",
    "    'Times Hit by Enemies': 'int32',\n",
    "    'Vehicle Type': 'string',\n",
    "    'World': 'string', \n",
    "    'Coins Spent in Toad Town': 'int32',\n",
    "    'Companion': 'string', \n",
    "    'Primary Game': 'string'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6c82d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_formats(df, expected_formats=expected_formats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603860f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_column_types(df, columns_types=expected_formats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93378728",
   "metadata": {},
   "outputs": [],
   "source": [
    "mario_misspelling = check_misspelling(df, 'Player Name', 0.8)\n",
    "mario_misspelling = mario_misspelling[\n",
    "    (mario_misspelling['name1'].str.lower() == 'mario') |\n",
    "    (mario_misspelling['name2'].str.lower() == 'mario')\n",
    "]\n",
    "\n",
    "mario_misspelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c8810",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_names = [\n",
    "    'Mario', 'Luigi', 'Peach', 'Daisy', 'Yoshi', 'Toad', 'Toadette', \n",
    "    'Rosalina', 'Wario', 'Waluigi', 'Bowser', 'Bowser Jr.'\n",
    "]\n",
    "rename_values = check_misspelling(df, 'Player Name', 0.8)\n",
    "rename_values = rename_values[\n",
    "    (rename_values['name1'].isin(valid_names)) | (rename_values['name2'].isin(valid_names))\n",
    "]\n",
    "\n",
    "rename_values['typo'] = rename_values.apply(\n",
    "    lambda r: r['name2'] if r['name1'] in valid_names else r['name1'], axis=1)\n",
    "rename_values['valid'] = rename_values.apply(\n",
    "    lambda r: r['name1'] if r['name1'] in valid_names else r['name2'], axis=1)\n",
    "\n",
    "rename_values = rename_values.sort_values('similarity', ascending=False).drop_duplicates('typo')\n",
    "\n",
    "renaming = dict(zip(rename_values['typo'], rename_values['valid']))\n",
    "\n",
    "df['Player Name'] = df['Player Name'].replace(renaming)\n",
    "sorted(df['Player Name'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c1aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_clean = ['Vehicle Type', 'World', 'Primary Game']\n",
    "\n",
    "cleaned = clean_spaces(df, cols_to_clean)\n",
    "\n",
    "cleaned[['Vehicle Type', 'World', 'Primary Game']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d43b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_title = ['Team', 'Companion', 'World']\n",
    "\n",
    "for col in cols_to_title:\n",
    "    df.loc[:, col] = df[col].astype(str).str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792111fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d42729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41398e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_formats(df, expected_formats=expected_formats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28be6521",
   "metadata": {},
   "source": [
    "## Step 5: Save Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd741472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('/silver/silver_mario.parquet', index = False) \n",
    "print(\"âœ… Cleaned data saved to Silver layer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
